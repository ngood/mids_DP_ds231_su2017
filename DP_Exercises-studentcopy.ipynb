{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MIDS Differential Privacy Assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definition: We say that a mechanism $M$ is $\\epsilon$-differential private if, for all databases $D$ and $D'$ that differ on exactly one element, and all measurable $S \\subseteq Codomain(M) $,\n",
    "\n",
    "$$ \\mathbb{P}(M(D) \\in S) \\le exp(\\epsilon)\\mathbb{P}(M(D') \\in S)$$\n",
    "\n",
    "By symmetry, an equivalent way to represent this is as\n",
    "\n",
    "$$ exp(-\\epsilon) \\le \\frac{\\mathbb{P}(M(D) \\in S)}{\\mathbb{P}(M(D') \\in S)} \\le exp(\\epsilon)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following questions are conceptual checks. Be as specific as possible with your justifications.\n",
    "\n",
    "(1) Could differential privacy have neutralized the Personal Project Genome attack?\n",
    "\n",
    "https://www.forbes.com/sites/adamtanner/2013/04/25/harvard-professor-re-identifies-anonymous-volunteers-in-dna-study/#6992f47e92c9\n",
    "\n",
    "(2) Suppose a database curator decides to \"protect\" privacy by randomly selecting one individual's record and publish that entry as the result. Their argument in favor of this is that \"there is low risk for an individual to be harmed in this mechanism.\" Explain how differential privacy protects against this type of information release, and why this type of release is terrible in general.\n",
    "\n",
    "(3) How does differential privacy address the fact that an individual's risk of identification increases every time the data is queried? How does this relate to the concept of privacy budget?\n",
    "\n",
    "(4) Suppose you know in advance that $K$ queries will be asked of a differentially private mechanism. What can you do to ensure a total privacy loss of $\\epsilon$?\n",
    "\n",
    "(5) What happens if you don't know how many queries will be asked of your differentially private mechanism. There could be 17 queries, or 3901 queries, or an unlimited amount. What can you do to ensure a total privacy loss of $\\epsilon$ over all queries?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Solution\n",
    "-- Write here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose we have access to a database of citizens in a county, containing information on whether or not an individual has commited a felony or not. Call this data $X$, such that $X[i] = 1$ if person $i$ has a criminal record. \n",
    "\n",
    "You receive a request from a client for information regarding how many people in the county have criminal records. Being the privacy-conscientious data scientist you are, you know the potential privacy implications of returning this true value. \n",
    "\n",
    "You explain to the client that you can give them a differentially private answer, but they are on the fence about the inaccuracies introduced via random noise insertion."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part A\n",
    "Explain to the client that there is a tradeoff between privacy and utility using simulaiton using the following array and candidate epsilon values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## This portion creates a dataset with 1200 folks without a criminal record, and 800 folks with one\n",
    "import numpy as np\n",
    "np.random.seed(0)\n",
    "\n",
    "x = np.asarray([0 for x in range(1200)] + [1 for x in range(800)])\n",
    "eps_list_1 = [0.010, 0.015, 0.020, 0.025, 0.030]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Solution\n",
    "-- Write here\n",
    "\n",
    "A suggestion is to implement a `laplace_counter` that returns a DP-answer and then a `simulation` function that calls the `laplace_counter` as many times as specified in order to simulate the result of multiple queries.\n",
    "\n",
    "Then plot the different results obtained when using each of the epsilons in `eps_list_1`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part B\n",
    "If we want to choose an $\\epsilon$ that is within $10$% of the truth value on average, which $\\epsilon$ should we choose? Explain your choice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Solution\n",
    "-- Write here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part C\n",
    "\n",
    "Suppose we go ahead and use the $\\epsilon$ from Part B. We'd like to be able to attach a confidence value that this specific $\\epsilon$ will be within $w$% of the truth. Desgin an algorithm to do this. What is the confidence we have for being within 10% of the truth?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Solution\n",
    "\n",
    "-- Write here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3\n",
    "\n",
    "(Building off of Exercise 2) Suppose now we are interested in the proportion of individuals with a criminal record, as opposed to a count. Furthermore, imagine that we want to build a general query system that takes in (1) the percent error an individual is willing to accept and (2) the confidence level they want for the result. \n",
    "\n",
    "Simulations are cool and all, but they are rather computationally expensive. Using elementary probability, create an algorithm that takes in (1) and (2) as inputs, and computes a differentially private estimate of the mean. Show your work for the derivation of the algorithm, and run a few test cases to verify that it indeed works."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Solution\n",
    "\n",
    "-- Write here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Exercise 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose we have a dataset of political party affiliation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## This portion creates a dataset with 2500 folks - 1K Republicans, 1.1K Democrats, and 400 Independents\n",
    "\n",
    "x = np.asarray([\"REPUB\" for x in range(1000)] + [\"DEMOC\" for x in range(1100)] + [\"INDEP\" for x in range(400)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to release a differentially private estimate of the mode with $\\epsilon$ = 0.1 \n",
    "\n",
    "(A) Write a function to do this. \n",
    "\n",
    "(B) Explain what differential privacy does to the underlying distribution of this categorical data.\n",
    "\n",
    "(C) Is \"INDEP\" more likely to occur with a large $\\epsilon$ or a small $\\epsilon$?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Solution\n",
    "-- Write here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EXTRA - DIFFERENTIAL PRIVACY WITH THE STOCHASTIC GRADIENT DESCENT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is an optional exercise that demonstrates how we can use differntial privacy in the machine learning training process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the MNIST dataset, build two classifiers to predict whether a given image is a 2 or a 3: one using logistic regression with stochastic gradient descent, and another using differentially private logistic regression with stochastic gradient descent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Note -- may need to do \n",
    "## pip install mnist\n",
    "## first\n",
    "import mnist\n",
    "\n",
    "print \"Success\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "print \"Success\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_mldata\n",
    "mnist_dataset = fetch_mldata('MNIST original')\n",
    "Y_2 = mnist_dataset['data'][np.where(mnist_dataset['target'] == 2.)[0]]\n",
    "Y_3 = mnist_dataset['data'][np.where(mnist_dataset['target'] == 3.)[0]]\n",
    "print 'number of twos:', Y_2.shape[0]\n",
    "print 'number of threes:', Y_3.shape[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = np.vstack([Y_2, Y_3])\n",
    "labels = np.asarray([0 for j in range(Y_2.shape[0])] + [1 for j in range(Y_3.shape[0])])\n",
    "\n",
    "print data.shape\n",
    "print labels.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following provides a guide of the structure to utilize for implementing Logistic Regression with DP-updates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Standard Logistic Regression \n",
    "\n",
    "## Logistic regression prediction function\n",
    "def log_reg_predict(coeff, x):\n",
    "    pass\n",
    "\n",
    "## Stochastic Gradient Descent for Logistic Regression\n",
    "def log_reg_coef_sgd(features, labels, l_rate, num_epochs):\n",
    "    ## remember to RANDOMLY SHUFFLE THE DATASET\n",
    "    pass\n",
    "\n",
    "## Differentially Private Stochastic Gradient Descent for Logistic Regression\n",
    "## http://cseweb.ucsd.edu/~kamalika/pubs/scs13.pdf\n",
    "## This paper shows the global sensitity for batch gradient descent of size b is 2.0 * learning_rate / b\n",
    "## Thus, for stochastic gradient descent, b = 1 => sensitivity of 2.0 * learning_rate\n",
    "def DP_log_reg_coef_sgd(features, labels, l_rate, num_epochs, eps):\n",
    "    ## remember to RANDOMLY SHUFFLE THE DATASET\n",
    "    pass\n",
    "\n",
    "print \"Utility functions loaded\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.33, random_state=42)\n",
    "\n",
    "print X_train.shape\n",
    "print y_train.shape\n",
    "print X_test.shape\n",
    "print y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "coeff = log_reg_coef_sgd(X_train, y_train, 1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def log_reg_scorer(X_train, y_train, X_test, y_test, l_rate, num_epochs, threshold):\n",
    "    ## Learn the coefficients    \n",
    "    ## Predict on the test set\n",
    "    ## Return the accuracy\n",
    "    pass\n",
    "\n",
    "print \"Scorer function loaded\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def DP_log_reg_scorer(X_train, y_train, X_test, y_test, l_rate, num_epochs, threshold, epsilon):\n",
    "    ## Learn the coefficients\n",
    "    ## Predict on the test set\n",
    "    ## Return the accuracy\n",
    "    pass\n",
    "\n",
    "print \"Scorer function loaded\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print log_reg_scorer(X_train, y_train, X_test, y_test, 1, 1, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sim_size = 10\n",
    "score_catcher = []\n",
    "for k in range(sim_size):\n",
    "    print \"simulation \" + str(k+1)  \n",
    "    score_catcher.append(DP_log_reg_scorer(X_train, y_train, X_test, y_test, 1, 1, 0.5, 0.1))\n",
    "    \n",
    "print np.mean(score_catcher)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
